
@article{good_c73._1980,
  title = {C73. {{The}} Diminishing Significance of a p-Value as the Sample Size Increases},
  volume = {11},
  issn = {0094-9655},
  number = {3-4},
  journal = {Journal of Statistical Computation and Simulation},
  doi = {10.1080/00949658008810416},
  author = {Good, I. J.},
  month = oct,
  year = {1980},
  pages = {307-313}
}

@article{good_c140._1982,
  title = {C140. {{Standardized}} Tail-Area Probabilities},
  volume = {16},
  issn = {0094-9655},
  number = {1},
  journal = {Journal of Statistical Computation and Simulation},
  doi = {10.1080/00949658208810607},
  author = {Good, I. J.},
  month = dec,
  year = {1982},
  pages = {65-66}
}

@article{good_lindleys_1982,
  title = {Lindley's Paradox: {{Comment}}},
  volume = {77},
  shorttitle = {Lindley's Paradox},
  number = {378},
  journal = {Journal of the American Statistical Association},
  author = {Good, I. J.},
  year = {1982},
  pages = {342--344}
}

@article{good_interface_1988,
  title = {The Interface between Statistics and Philosophy of Science},
  volume = {3},
  number = {4},
  journal = {Statistical Science},
  author = {Good, I. J.},
  year = {1988},
  pages = {386--397}
}

@article{good_bayes/non-bayes_1992,
  title = {The {{Bayes}}/{{Non}}-{{Bayes Compromise}}: {{A Brief Review}}},
  volume = {87},
  issn = {01621459},
  shorttitle = {The {{Bayes}}/{{Non}}-{{Bayes Compromise}}},
  number = {419},
  journal = {Journal of the American Statistical Association},
  doi = {10.2307/2290192},
  author = {Good, I. J.},
  month = sep,
  year = {1992},
  pages = {597}
}

@book{ravetz_scientific_1995,
  address = {{New Brunswick, N.J}},
  edition = {Reprint edition},
  title = {Scientific {{Knowledge}} and {{Its Social Problems}}},
  isbn = {978-1-56000-851-4},
  abstract = {Science is continually confronted by new and difficult social and ethical problems. Some of these problems have arisen from the transformation of the academic science of the prewar period into the industrialized science of the present. Traditional theories of science are now widely recognized as obsolete. In Scientific Knowledge and Its Social Problems (originally published in 1971), Jerome R. Ravetz analyzes the work of science as the creation and investigation of problems. He demonstrates the role of choice and value judgment, and the inevitability of error, in scientific research. Ravetz's new introductory essay is a masterful statement of how our understanding of science has evolved over the last two decades.},
  language = {English},
  publisher = {{Transaction Publishers}},
  author = {Ravetz, Jerome},
  month = jan,
  year = {1995}
}

@article{lakens_justify_2018,
  title = {Justify Your Alpha},
  volume = {2},
  copyright = {2018 The Publisher},
  issn = {2397-3374},
  abstract = {In response to recommendations to redefine statistical significance to P {$\leq$} 0.005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.},
  language = {en},
  journal = {Nature Human Behaviour},
  doi = {10.1038/s41562-018-0311-x},
  author = {Lakens, Dani{\"e}l and Adolfi, Federico G. and Albers, Casper J. and Anvari, Farid and Apps, Matthew A. J. and Argamon, Shlomo E. and Baguley, Thom and Becker, Raymond B. and Benning, Stephen D. and Bradford, Daniel E. and Buchanan, Erin M. and Caldwell, Aaron R. and Calster, Ben and Carlsson, Rickard and Chen, Sau-Chin and Chung, Bryan and Colling, Lincoln J. and Collins, Gary S. and Crook, Zander and Cross, Emily S. and Daniels, Sameera and Danielsson, Henrik and DeBruine, Lisa and Dunleavy, Daniel J. and Earp, Brian D. and Feist, Michele I. and Ferrell, Jason D. and Field, James G. and Fox, Nicholas W. and Friesen, Amanda and Gomes, Caio and {Gonzalez-Marquez}, Monica and Grange, James A. and Grieve, Andrew P. and Guggenberger, Robert and Grist, James and Harmelen, Anne-Laura and Hasselman, Fred and Hochard, Kevin D. and Hoffarth, Mark R. and Holmes, Nicholas P. and Ingre, Michael and Isager, Peder M. and Isotalus, Hanna K. and Johansson, Christer and Juszczyk, Konrad and Kenny, David A. and Khalil, Ahmed A. and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M. A. and Lukavsk{\'y}, Ji{\v r}{\'i} and Madan, Christopher R. and Manheim, David and Martin, Stephen R. and Martin, Andrea E. and Mayo, Deborah G. and McCarthy, Randy J. and McConway, Kevin and McFarland, Colin and Nio, Amanda Q. X. and Nilsonne, Gustav and Oliveira, Cilene Lino and Xivry, Jean-Jacques Orban and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly A. and Sakon, John J. and Saribay, S. Adil and Schneider, Iris K. and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel G. and Smits, Tim and Spies, Jeffrey R. and Sreekumar, Vishnu and Steltenpohl, Crystal N. and Stenhouse, Neil and {\'S}wi{\k{a}}tkowski, Wojciech and Vadillo, Miguel A. and Assen, Marcel A. L. M. and Williams, Matt N. and Williams, Samantha E. and Williams, Donald R. and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf A.},
  month = feb,
  year = {2018},
  pages = {168-171},
  note = {00010}
}

@book{zellner_introduction_1971,
  address = {{New York}},
  series = {Wiley Series in Probability and Mathematical Statistics},
  title = {An Introduction to {{Bayesian}} Inference in Econometrics},
  isbn = {978-0-471-98165-7},
  lccn = {HB74.M3 Z44},
  publisher = {{Wiley}},
  author = {Zellner, Arnold},
  year = {1971},
  keywords = {Econometrics,Bayesian statistical decision theory}
}

@article{berger_testing_1987,
  title = {Testing a Point Null Hypothesis: The Irreconcilability of {{P}} Values and Evidence},
  volume = {82},
  shorttitle = {Testing a Point Null Hypothesis},
  number = {397},
  journal = {Journal of the American statistical Association},
  author = {Berger, James O. and Sellke, Thomas},
  year = {1987},
  pages = {112--122}
}

@article{gigerenzer_statistical_2018,
  title = {Statistical {{Rituals}}: {{The Replication Delusion}} and {{How We Got There}}},
  issn = {2515-2459},
  shorttitle = {Statistical {{Rituals}}},
  abstract = {The ``replication crisis'' has been attributed to misguided external incentives gamed by researchers (the strategic-game hypothesis). Here, I want to draw attention to a complementary internal factor, namely, researchers' widespread faith in a statistical ritual and associated delusions (the statistical-ritual hypothesis). The ``null ritual,'' unknown in statistics proper, eliminates judgment precisely at points where statistical theories demand it. The crucial delusion is that the p value specifies the probability of a successful replication (i.e., 1 \textendash{} p), which makes replication studies appear to be superfluous. A review of studies with 839 academic psychologists and 991 students shows that the replication delusion existed among 20\% of the faculty teaching statistics in psychology, 39\% of the professors and lecturers, and 66\% of the students. Two further beliefs, the illusion of certainty (e.g., that statistical significance proves that an effect exists) and Bayesian wishful thinking (e.g., that the probability of the alternative hypothesis being true is 1 \textendash{} p), also make successful replication appear to be certain or almost certain, respectively. In every study reviewed, the majority of researchers (56\%\textendash{}97\%) exhibited one or more of these delusions. Psychology departments need to begin teaching statistical thinking, not rituals, and journal editors should no longer accept manuscripts that report results as ``significant'' or ``not significant.''},
  language = {en},
  journal = {Advances in Methods and Practices in Psychological Science},
  doi = {10.1177/2515245918771329},
  author = {Gigerenzer, Gerd},
  month = jun,
  year = {2018},
  pages = {2515245918771329},
  note = {00000}
}

@article{bakan_test_1966,
  title = {The Test of Significance in Psychological Research.},
  volume = {66},
  number = {6},
  journal = {Psychological bulletin},
  author = {Bakan, David},
  year = {1966},
  pages = {423-437}
}

@article{skipper_sacredness_1967,
  title = {The {{Sacredness}} of .05: {{A Note}} Concerning the {{Uses}} of {{Statistical Levels}} of {{Significance}} in {{Social Science}}},
  volume = {2},
  issn = {0003-1232},
  shorttitle = {The {{Sacredness}} of .05},
  number = {1},
  journal = {The American Sociologist},
  author = {Skipper, James K. and Guenther, Anthony L. and Nass, Gilbert},
  year = {1967},
  pages = {16-18}
}

@article{cowles_origins_1982,
  title = {On the Origins of the. 05 Level of Statistical Significance.},
  volume = {37},
  number = {5},
  journal = {American Psychologist},
  author = {Cowles, Michael and Davis, Caroline},
  year = {1982},
  pages = {553}
}

@book{fisher_design_1935,
  title = {The Design of Experiments},
  publisher = {{Oliver And Boyd; Edinburgh; London}},
  author = {Fisher, Ronald Aylmer},
  year = {1935}
}

@article{fisher_introduction_1926,
  title = {Introduction to ``{{The}} Arrangement of Field Experiments''},
  volume = {33},
  journal = {Journal of the Ministry of Agriculture},
  author = {Fisher, R. A.},
  year = {1926},
  pages = {503--513}
}

@article{lindley_statistical_1957,
  title = {A Statistical Paradox},
  volume = {44},
  number = {1/2},
  journal = {Biometrika},
  author = {Lindley, Dennis V.},
  year = {1957},
  pages = {187--192}
}

@article{cousins_jeffreyslindley_2017,
  title = {The {{Jeffreys}}\textendash{{Lindley}} Paradox and Discovery Criteria in High Energy Physics},
  volume = {194},
  issn = {0039-7857, 1573-0964},
  abstract = {The Jeffreys\textendash{}Lindley paradox displays how the use of a ppp value (or number of standard deviations zzz) in a frequentist hypothesis test can lead to an inference that is radically different from that of a Bayesian hypothesis test in the form advocated by Harold Jeffreys in the 1930s and common today. The setting is the test of a well-specified null hypothesis (such as the Standard Model of elementary particle physics, possibly with ``nuisance parameters'') versus a composite alternative (such as the Standard Model plus a new force of nature of unknown strength). The ppp value, as well as the ratio of the likelihood under the null hypothesis to the maximized likelihood under the alternative, can strongly disfavor the null hypothesis, while the Bayesian posterior probability for the null hypothesis can be arbitrarily large. The academic statistics literature contains many impassioned comments on this paradox, yet there is no consensus either on its relevance to scientific communication or on its correct resolution. The paradox is quite relevant to frontier research in high energy physics. This paper is an attempt to explain the situation to both physicists and statisticians, in the hope that further progress can be made.},
  language = {en},
  number = {2},
  journal = {Synthese},
  doi = {10.1007/s11229-014-0525-z},
  author = {Cousins, Robert D.},
  month = feb,
  year = {2017},
  pages = {395-432},
  note = {00028}
}

@article{neyman_problem_1933,
  title = {On the {{Problem}} of the {{Most Efficient Tests}} of {{Statistical Hypotheses}}},
  volume = {231},
  issn = {1364-503X, 1471-2962},
  language = {en},
  number = {694-706},
  journal = {Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
  doi = {10.1098/rsta.1933.0009},
  author = {Neyman, J. and Pearson, E. S.},
  month = jan,
  year = {1933},
  pages = {289-337}
}

@book{cohen_statistical_1988,
  address = {{Hillsdale, N.J}},
  edition = {2nd ed},
  title = {Statistical Power Analysis for the Behavioral Sciences},
  isbn = {978-0-8058-0283-2},
  lccn = {HA29 .C66 1988},
  publisher = {{L. Erlbaum Associates}},
  author = {Cohen, Jacob},
  year = {1988},
  keywords = {Statistical methods,Social sciences,Probabilities,Statistical power analysis}
}

@book{leamer_specification_1978,
  address = {{New York usw.}},
  edition = {1 edition},
  title = {Specification {{Searches}}: {{Ad Hoc Inference}} with {{Nonexperimental Data}}},
  isbn = {978-0-471-01520-8},
  shorttitle = {Specification {{Searches}}},
  abstract = {Offers a radically new approach to inference with nonexperimental data when the statistical model is ambiguously defined. Examines the process of model searching and its implications for inference. Identifies six different varieties of specification searches, discussing the inferential consequences of each in detail.},
  language = {English},
  publisher = {{Wiley}},
  author = {Leamer, Edward E.},
  month = apr,
  year = {1978}
}

@article{rouder_bayesian_2009,
  title = {Bayesian t Tests for Accepting and Rejecting the Null Hypothesis},
  volume = {16},
  issn = {1069-9384, 1531-5320},
  language = {en},
  number = {2},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/PBR.16.2.225},
  author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
  month = apr,
  year = {2009},
  pages = {225-237},
  note = {01475}
}

@book{jeffreys_theory_1939,
  address = {{Oxford [Oxfordshire] : New York}},
  edition = {1st ed},
  series = {The {{International}} Series of Monographs on Physics},
  title = {Theory of Probability},
  isbn = {978-0-19-853193-7},
  lccn = {QA273 .J4 1983},
  publisher = {{Clarendon Press ; Oxford University Press}},
  author = {Jeffreys, Harold},
  year = {1939},
  keywords = {Probabilities}
}

@article{berger_unified_1997,
  title = {Unified Frequentist and {{Bayesian}} Testing of a Precise Hypothesis},
  volume = {12},
  number = {3},
  journal = {Statistical Science},
  author = {Berger, James O. and Boukai, Ben and Wang, Yinping and others},
  year = {1997},
  pages = {133--160}
}

@article{benjamin_redefine_2018,
  title = {Redefine Statistical Significance},
  volume = {2},
  copyright = {2017 The Author(s)},
  issn = {2397-3374},
  abstract = {We propose to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.},
  language = {en},
  number = {1},
  journal = {Nature Human Behaviour},
  doi = {10.1038/S41562-017-0189-Z},
  author = {Benjamin, Daniel J. and Berger, James O. and Johannesson, Magnus and Nosek, Brian A. and Wagenmakers, E.-J. and Berk, Richard and Bollen, Kenneth A. and Brembs, Bj{\"o}rn and Brown, Lawrence and Camerer, Colin and Cesarini, David and Chambers, Christopher D. and Clyde, Merlise and Cook, Thomas D. and Boeck, Paul De and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P. and Forster, Malcolm and George, Edward I. and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P. and Greenwald, Anthony G. and Hadfield, Jarrod D. and Hedges, Larry V. and Held, Leonhard and Ho, Teck Hua and Hoijtink, Herbert and Hruschka, Daniel J. and Imai, Kosuke and Imbens, Guido and Ioannidis, John P. A. and Jeon, Minjeong and Jones, James Holland and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E. and McCarthy, Michael and Moore, Don A. and Morgan, Stephen L. and Munaf{\'o}, Marcus and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H. and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and Sch{\"o}nbrodt, Felix D. and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and Zandt, Trisha Van and Vazire, Simine and Watts, Duncan J. and Winship, Christopher and Wolpert, Robert L. and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E.},
  month = jan,
  year = {2018},
  pages = {6-10},
  note = {00170}
}

@article{sellke_calibration_2001,
  title = {Calibration of {$\rho$} Values for Testing Precise Null Hypotheses},
  volume = {55},
  number = {1},
  journal = {The American Statistician},
  author = {Sellke, Thomas and Bayarri, M. J. and Berger, James O.},
  year = {2001},
  pages = {62--71}
}

@article{senn_two_2001,
  title = {Two Cheers for {{P}}-Values?},
  volume = {6},
  number = {2},
  journal = {Journal of Epidemiology and Biostatistics},
  author = {Senn, S.},
  year = {2001},
  pages = {193--204}
}

@article{mudge_setting_2012,
  title = {Setting an {{Optimal}} {$\alpha$} {{That Minimizes Errors}} in {{Null Hypothesis Significance Tests}}},
  volume = {7},
  issn = {1932-6203},
  abstract = {Null hypothesis significance testing has been under attack in recent years, partly owing to the arbitrary nature of setting {$\alpha$} (the decision-making threshold and probability of Type I error) at a constant value, usually 0.05. If the goal of null hypothesis testing is to present conclusions in which we have the highest possible confidence, then the only logical decision-making threshold is the value that minimizes the probability (or occasionally, cost) of making errors. Setting {$\alpha$} to minimize the combination of Type I and Type II error at a critical effect size can easily be accomplished for traditional statistical tests by calculating the {$\alpha$} associated with the minimum average of {$\alpha$} and {$\beta$} at the critical effect size. This technique also has the flexibility to incorporate prior probabilities of null and alternate hypotheses and/or relative costs of Type I and Type II errors, if known. Using an optimal {$\alpha$} results in stronger scientific inferences because it estimates and minimizes both Type I errors and relevant Type II errors for a test. It also results in greater transparency concerning assumptions about relevant effect size(s) and the relative costs of Type I and II errors. By contrast, the use of {$\alpha$} = 0.05 results in arbitrary decisions about what effect sizes will likely be considered significant, if real, and results in arbitrary amounts of Type II error for meaningful potential effect sizes. We cannot identify a rationale for continuing to arbitrarily use {$\alpha$} = 0.05 for null hypothesis significance tests in any field, when it is possible to determine an optimal {$\alpha$}.},
  number = {2},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0032734},
  author = {Mudge, Joseph F. and Baker, Leanne F. and Edge, Christopher B. and Houlahan, Jeff E.},
  month = feb,
  year = {2012},
  keywords = {Decision making,Experimental design,Freshwater fish,Lakes,Research errors,Gene expression,Shores,Agricultural soil science},
  pages = {e32734}
}

@article{field_minimizing_2004,
  title = {Minimizing the Cost of Environmental Management Decisions by Optimizing Statistical Thresholds},
  volume = {7},
  number = {8},
  journal = {Ecology Letters},
  author = {Field, Scott A. and Tyre, Andrew J. and Jonz{\'e}n, Niclas and Rhodes, Jonathan R. and Possingham, Hugh P.},
  year = {2004},
  pages = {669--675}
}

@book{winer_statistical_1962,
  title = {Statistical Principles in Experimental Design},
  abstract = {"Written primarily for students and research workers in the area of the behavioral sciences, this book is meant to provide a text and comprehensive reference source on statistical principles underlying experimental design. Particular emphasis is given to those designs that are likely to prove useful in research in the behavioral sciences. The book primarily emphasizes the logical basis of principles underlying designs for experiments rather than mathematical derivations associated with relevant sampling distributions. The topics selected for inclusion are those covered in courses taught by the author during the past several years. Students in these courses have widely varying backgrounds in mathematics and come primarily from the fields of psychology, education, economics, sociology, and industrial engineering. It has been the intention of the author to keep the book at a readability level appropriate for students having a mathematical background equivalent to freshman college algebra. From experience with those sections of the book which have been used as text material in dittoed form, there is evidence to indicate that, in large measure, the desired readability level has been attained. Admittedly, however, there are some sections in the book where this readability goal has not been achieved. The first course in design, as taught by the author, has as a prerequisite a basic course in statistical inference. The contents of Chaps. 1 and 2 review the highlights of what is included in the prerequisite material. These chapters are not meant to provide the reader with a first exposure to these topics. They are intended to provide a review of terminology and notation for the concepts which are more fully developed in later chapters. By no means is all the material included in the book covered in a one semester course. In a course of this length, the author has included Chaps. 3, 4, parts of 5, 6, parts of 7, parts of 10, and parts of 11. Chapters 8 through 11 were written to be somewhat independent of each other. Hence one may read, with understanding, in these chapters without undue reference to material in the others. In general, the discussion of principles, interpretations of illustrative examples, and computational procedures are included in successive sections within the same chapter. However, to facilitate the use of the book as a reference source, this procedure is not followed in Chaps. 5 and 6. Basic principles associated with a large class of designs for factorial experiments are discussed in Chap. 5. Detailed illustrative examples of these designs are presented in Chap. 6. For teaching purposes, the author includes relevant material from Chap. 6 with the corresponding material in Chap. 5. Selected topics from Chaps. 7 through 11 have formed the basis for a second course in experimental design. Relatively complete tables for sampling distributions of statistics used in the analysis of experimental designs are included in the Appendix. Ample references to source materials having mathematical proofs for the principles stated in the text are provided"--Preface. (PsycINFO Database Record (c) 2008 APA, all rights reserved).  x, 672 p. : ill. ; 24 cm. Social sciences -- Statistical methods. Psychology -- Statistical methods. Research. Plan d'exp{\'e}rience. Experimentelle Psychologie. Statistik. Versuchsplanung. Psychology -- Research. Social sciences -- Research. Experimenteel ontwerp. Variantieanalyse. Experimental design. Statistics as Topic.},
  language = {English},
  publisher = {{New York : McGraw-Hill}},
  author = {Winer, B. J},
  year = {1962}
}

@article{miller_quest_2019,
  title = {The Quest for an Optimal Alpha},
  volume = {14},
  issn = {1932-6203},
  abstract = {Researchers who analyze data within the framework of null hypothesis significance testing must choose a critical ``alpha'' level, {$\alpha$}, to use as a cutoff for deciding whether a given set of data demonstrates the presence of a particular effect. In most fields, {$\alpha$} = 0.05 has traditionally been used as the standard cutoff. Many researchers have recently argued for a change to a more stringent evidence cutoff such as {$\alpha$} = 0.01, 0.005, or 0.001, noting that this change would tend to reduce the rate of false positives, which are of growing concern in many research areas. Other researchers oppose this proposed change, however, because it would correspondingly tend to increase the rate of false negatives. We show how a simple statistical model can be used to explore the quantitative tradeoff between reducing false positives and increasing false negatives. In particular, the model shows how the optimal {$\alpha$} level depends on numerous characteristics of the research area, and it reveals that although {$\alpha$} = 0.05 would indeed be approximately the optimal value in some realistic situations, the optimal {$\alpha$} could actually be substantially larger or smaller in other situations. The importance of the model lies in making it clear what characteristics of the research area have to be specified to make a principled argument for using one {$\alpha$} level rather than another, and the model thereby provides a blueprint for researchers seeking to justify a particular {$\alpha$} level.},
  language = {en},
  number = {1},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0208631},
  author = {Miller, Jeff and Ulrich, Rolf},
  month = jan,
  year = {2019},
  keywords = {Statistical methods,Psychology,Medicine and health sciences,Health economics,Publication ethics,Decision theory,Economic growth,Statistical models},
  pages = {e0208631},
  note = {00000}
}


